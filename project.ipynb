{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thomas Dougherty\n",
    "\n",
    "Probability and Statistics for Computer Science\n",
    "\n",
    "\n",
    "Introduction\n",
    "\n",
    "    To Do:\n",
    "\n",
    "    Figure out script to iterate through and cleanup all CSVs\n",
    "\n",
    "    Store data from all CSVs\n",
    "\n",
    "    Aggregate data from *all* CSVs into one dataframe\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>train_id</th>\n",
       "      <th>stop_sequence</th>\n",
       "      <th>from</th>\n",
       "      <th>from_id</th>\n",
       "      <th>to</th>\n",
       "      <th>to_id</th>\n",
       "      <th>scheduled_time</th>\n",
       "      <th>actual_time</th>\n",
       "      <th>delay_minutes</th>\n",
       "      <th>line</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>3805</td>\n",
       "      <td>1.0</td>\n",
       "      <td>New York Penn Station</td>\n",
       "      <td>105</td>\n",
       "      <td>New York Penn Station</td>\n",
       "      <td>105</td>\n",
       "      <td>2018-03-02 01:22:00</td>\n",
       "      <td>2018-03-02 01:21:05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Northeast Corrdr</td>\n",
       "      <td>NJ Transit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>3805</td>\n",
       "      <td>2.0</td>\n",
       "      <td>New York Penn Station</td>\n",
       "      <td>105</td>\n",
       "      <td>Secaucus Upper Lvl</td>\n",
       "      <td>38187</td>\n",
       "      <td>2018-03-02 01:31:00</td>\n",
       "      <td>2018-03-02 01:31:08</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>Northeast Corrdr</td>\n",
       "      <td>NJ Transit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>3805</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Secaucus Upper Lvl</td>\n",
       "      <td>38187</td>\n",
       "      <td>Newark Penn Station</td>\n",
       "      <td>107</td>\n",
       "      <td>2018-03-02 01:40:00</td>\n",
       "      <td>2018-03-02 01:40:07</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>Northeast Corrdr</td>\n",
       "      <td>NJ Transit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>3805</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Newark Penn Station</td>\n",
       "      <td>107</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>37953</td>\n",
       "      <td>2018-03-02 01:45:00</td>\n",
       "      <td>2018-03-02 01:45:10</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>Northeast Corrdr</td>\n",
       "      <td>NJ Transit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>3805</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>37953</td>\n",
       "      <td>North Elizabeth</td>\n",
       "      <td>109</td>\n",
       "      <td>2018-03-02 01:49:00</td>\n",
       "      <td>2018-03-02 01:49:10</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>Northeast Corrdr</td>\n",
       "      <td>NJ Transit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>3805</td>\n",
       "      <td>6.0</td>\n",
       "      <td>North Elizabeth</td>\n",
       "      <td>109</td>\n",
       "      <td>Elizabeth</td>\n",
       "      <td>41</td>\n",
       "      <td>2018-03-02 01:52:00</td>\n",
       "      <td>2018-03-02 01:52:01</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>Northeast Corrdr</td>\n",
       "      <td>NJ Transit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>3805</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Elizabeth</td>\n",
       "      <td>41</td>\n",
       "      <td>Linden</td>\n",
       "      <td>70</td>\n",
       "      <td>2018-03-02 01:58:00</td>\n",
       "      <td>2018-03-02 01:58:05</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>Northeast Corrdr</td>\n",
       "      <td>NJ Transit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>3805</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Linden</td>\n",
       "      <td>70</td>\n",
       "      <td>Rahway</td>\n",
       "      <td>127</td>\n",
       "      <td>2018-03-02 02:02:00</td>\n",
       "      <td>2018-03-02 02:01:03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Northeast Corrdr</td>\n",
       "      <td>NJ Transit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>3805</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Rahway</td>\n",
       "      <td>127</td>\n",
       "      <td>Metropark</td>\n",
       "      <td>83</td>\n",
       "      <td>2018-03-02 02:08:00</td>\n",
       "      <td>2018-03-02 02:08:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Northeast Corrdr</td>\n",
       "      <td>NJ Transit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>3805</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Metropark</td>\n",
       "      <td>83</td>\n",
       "      <td>Metuchen</td>\n",
       "      <td>84</td>\n",
       "      <td>2018-03-02 02:13:00</td>\n",
       "      <td>2018-03-02 02:13:10</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>Northeast Corrdr</td>\n",
       "      <td>NJ Transit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date train_id  stop_sequence                   from  from_id  \\\n",
       "0  2018-03-01     3805            1.0  New York Penn Station      105   \n",
       "1  2018-03-01     3805            2.0  New York Penn Station      105   \n",
       "2  2018-03-01     3805            3.0     Secaucus Upper Lvl    38187   \n",
       "3  2018-03-01     3805            4.0    Newark Penn Station      107   \n",
       "4  2018-03-01     3805            5.0         Newark Airport    37953   \n",
       "5  2018-03-01     3805            6.0        North Elizabeth      109   \n",
       "6  2018-03-01     3805            7.0              Elizabeth       41   \n",
       "7  2018-03-01     3805            8.0                 Linden       70   \n",
       "8  2018-03-01     3805            9.0                 Rahway      127   \n",
       "9  2018-03-01     3805           10.0              Metropark       83   \n",
       "\n",
       "                      to  to_id       scheduled_time          actual_time  \\\n",
       "0  New York Penn Station    105  2018-03-02 01:22:00  2018-03-02 01:21:05   \n",
       "1     Secaucus Upper Lvl  38187  2018-03-02 01:31:00  2018-03-02 01:31:08   \n",
       "2    Newark Penn Station    107  2018-03-02 01:40:00  2018-03-02 01:40:07   \n",
       "3         Newark Airport  37953  2018-03-02 01:45:00  2018-03-02 01:45:10   \n",
       "4        North Elizabeth    109  2018-03-02 01:49:00  2018-03-02 01:49:10   \n",
       "5              Elizabeth     41  2018-03-02 01:52:00  2018-03-02 01:52:01   \n",
       "6                 Linden     70  2018-03-02 01:58:00  2018-03-02 01:58:05   \n",
       "7                 Rahway    127  2018-03-02 02:02:00  2018-03-02 02:01:03   \n",
       "8              Metropark     83  2018-03-02 02:08:00  2018-03-02 02:08:00   \n",
       "9               Metuchen     84  2018-03-02 02:13:00  2018-03-02 02:13:10   \n",
       "\n",
       "   delay_minutes              line        type  \n",
       "0       0.000000  Northeast Corrdr  NJ Transit  \n",
       "1       0.133333  Northeast Corrdr  NJ Transit  \n",
       "2       0.116667  Northeast Corrdr  NJ Transit  \n",
       "3       0.166667  Northeast Corrdr  NJ Transit  \n",
       "4       0.166667  Northeast Corrdr  NJ Transit  \n",
       "5       0.016667  Northeast Corrdr  NJ Transit  \n",
       "6       0.083333  Northeast Corrdr  NJ Transit  \n",
       "7       0.000000  Northeast Corrdr  NJ Transit  \n",
       "8       0.000000  Northeast Corrdr  NJ Transit  \n",
       "9       0.166667  Northeast Corrdr  NJ Transit  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from helper_functions import *\n",
    "\n",
    "#read CSV for March 2018\n",
    "services = pd.read_csv('data\\\\2018_03.csv',index_col=False)\n",
    "\n",
    "#status column is not needed so that will be dropped\n",
    "services.drop(labels=['status'], axis=1, inplace=True)\n",
    "# Amtrak rows are dropped because OTP of Amtrak was not tracked in the dataset\n",
    "services.drop(services[services['type'] == 'Amtrak'].index, inplace=True)\n",
    "services.astype({'date' : 'datetime64',\n",
    "                'train_id' : 'category',\n",
    "                'stop_sequence' : 'float16',\n",
    "                'from' : 'category',\n",
    "                'from_id': 'category',\n",
    "                'to' : 'category',\n",
    "                'to_id': 'category',\n",
    "                'scheduled_time' : 'datetime64',\n",
    "                'actual_time' : 'datetime64',\n",
    "                'delay_minutes' : 'float16',\n",
    "                'line' : 'category',\n",
    "                'type' : 'category'})\n",
    "services.dtypes\n",
    "services.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         89468    2018-03-12\n",
      "Name: date, dtype: object\n",
      "1          4655    2018-03-01\n",
      "Name: date, dtype: object\n",
      "2     52565    2018-03-07\n",
      "52566    2018-03-07\n",
      "52567 ...\n",
      "3         11067    2018-03-02\n",
      "Name: date, dtype: object\n",
      "4         15026    2018-03-02\n",
      "Name: date, dtype: object\n",
      "5     55882    2018-03-07\n",
      "55885    2018-03-07\n",
      "55886 ...\n",
      "6     54531    2018-03-07\n",
      "54533    2018-03-07\n",
      "54534 ...\n",
      "7         55508    2018-03-07\n",
      "Name: date, dtype: object\n",
      "8         54448    2018-03-07\n",
      "Name: date, dtype: object\n",
      "9         29514    2018-03-04\n",
      "Name: date, dtype: object\n",
      "10        53170    2018-03-07\n",
      "Name: date, dtype: object\n",
      "dtype: object\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "<class 'pandas.core.series.Series'> is not convertible to datetime",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 13\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mprint\u001b[39m(dates)\n\u001b[0;32m      8\u001b[0m performance_by_line \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({\u001b[39m'\u001b[39m\u001b[39mLongest Delay (minutes)\u001b[39m\u001b[39m'\u001b[39m: max_delays\u001b[39m.\u001b[39mvalues,\n\u001b[0;32m      9\u001b[0m                                   \u001b[39m'\u001b[39m\u001b[39mAverage Delay (minutes)\u001b[39m\u001b[39m'\u001b[39m: avg_delays\u001b[39m.\u001b[39mvalues,\n\u001b[0;32m     10\u001b[0m                                   \u001b[39m'\u001b[39m\u001b[39mDate of Longest Delay\u001b[39m\u001b[39m'\u001b[39m : dates\u001b[39m.\u001b[39mvalues},\n\u001b[0;32m     11\u001b[0m                                    index\u001b[39m=\u001b[39mnjt_lines)\n\u001b[1;32m---> 13\u001b[0m performance_by_line\u001b[39m.\u001b[39;49mastype({\u001b[39m'\u001b[39;49m\u001b[39mLongest Delay (minutes)\u001b[39;49m\u001b[39m'\u001b[39;49m :\u001b[39m'\u001b[39;49m\u001b[39mfloat16\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     14\u001b[0m                            \u001b[39m'\u001b[39;49m\u001b[39mAverage Delay (minutes)\u001b[39;49m\u001b[39m'\u001b[39;49m :\u001b[39m'\u001b[39;49m\u001b[39mfloat16\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     15\u001b[0m                            \u001b[39m'\u001b[39;49m\u001b[39mDate of Longest Delay\u001b[39;49m\u001b[39m'\u001b[39;49m : \u001b[39m'\u001b[39;49m\u001b[39mdatetime64\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[0;32m     16\u001b[0m                            })\n\u001b[0;32m     18\u001b[0m performance_by_line\n",
      "File \u001b[1;32mc:\\Users\\tdoug\\miniconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\generic.py:6226\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6224\u001b[0m             res_col \u001b[39m=\u001b[39m col\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m copy \u001b[39melse\u001b[39;00m col\n\u001b[0;32m   6225\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 6226\u001b[0m             res_col \u001b[39m=\u001b[39m col\u001b[39m.\u001b[39;49mastype(dtype\u001b[39m=\u001b[39;49mcdt, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   6227\u001b[0m         results\u001b[39m.\u001b[39mappend(res_col)\n\u001b[0;32m   6229\u001b[0m \u001b[39melif\u001b[39;00m is_extension_array_dtype(dtype) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   6230\u001b[0m     \u001b[39m# GH 18099/22869: columnwise conversion to extension dtype\u001b[39;00m\n\u001b[0;32m   6231\u001b[0m     \u001b[39m# GH 24704: use iloc to handle duplicate column names\u001b[39;00m\n\u001b[0;32m   6232\u001b[0m     \u001b[39m# TODO(EA2D): special case not needed with 2D EAs\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tdoug\\miniconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\generic.py:6240\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6233\u001b[0m     results \u001b[39m=\u001b[39m [\n\u001b[0;32m   6234\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miloc[:, i]\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m   6235\u001b[0m         \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns))\n\u001b[0;32m   6236\u001b[0m     ]\n\u001b[0;32m   6238\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   6239\u001b[0m     \u001b[39m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6240\u001b[0m     new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mastype(dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   6241\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor(new_data)\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mastype\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6243\u001b[0m \u001b[39m# GH 33113: handle empty frame or series\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tdoug\\miniconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\internals\\managers.py:450\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mastype\u001b[39m(\u001b[39mself\u001b[39m: T, dtype, copy: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, errors: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m--> 450\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply(\u001b[39m\"\u001b[39;49m\u001b[39mastype\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n",
      "File \u001b[1;32mc:\\Users\\tdoug\\miniconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\internals\\managers.py:352\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m         applied \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39mapply(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    351\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 352\u001b[0m         applied \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(b, f)(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mNotImplementedError\u001b[39;00m):\n\u001b[0;32m    354\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ignore_failures:\n",
      "File \u001b[1;32mc:\\Users\\tdoug\\miniconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:526\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[39mCoerce to the new dtype.\u001b[39;00m\n\u001b[0;32m    510\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[39mBlock\u001b[39;00m\n\u001b[0;32m    523\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    524\u001b[0m values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues\n\u001b[1;32m--> 526\u001b[0m new_values \u001b[39m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m    528\u001b[0m new_values \u001b[39m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    529\u001b[0m newb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_block(new_values)\n",
      "File \u001b[1;32mc:\\Users\\tdoug\\miniconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:299\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[39mreturn\u001b[39;00m values\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m    298\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 299\u001b[0m     new_values \u001b[39m=\u001b[39m astype_array(values, dtype, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[0;32m    300\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[0;32m    301\u001b[0m     \u001b[39m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    302\u001b[0m     \u001b[39m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    303\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\tdoug\\miniconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:230\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    227\u001b[0m     values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m    229\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m     values \u001b[39m=\u001b[39m astype_nansafe(values, dtype, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[0;32m    232\u001b[0m \u001b[39m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, np\u001b[39m.\u001b[39mdtype) \u001b[39mand\u001b[39;00m \u001b[39missubclass\u001b[39m(values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\tdoug\\miniconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:151\u001b[0m, in \u001b[0;36mastype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[39mif\u001b[39;00m is_datetime64_dtype(dtype):\n\u001b[0;32m    148\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mimport\u001b[39;00m to_datetime\n\u001b[0;32m    150\u001b[0m     \u001b[39mreturn\u001b[39;00m astype_nansafe(\n\u001b[1;32m--> 151\u001b[0m         to_datetime(arr\u001b[39m.\u001b[39;49mravel())\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mreshape(arr\u001b[39m.\u001b[39mshape),\n\u001b[0;32m    152\u001b[0m         dtype,\n\u001b[0;32m    153\u001b[0m         copy\u001b[39m=\u001b[39mcopy,\n\u001b[0;32m    154\u001b[0m     )\n\u001b[0;32m    155\u001b[0m \u001b[39melif\u001b[39;00m is_timedelta64_dtype(dtype):\n\u001b[0;32m    156\u001b[0m     \u001b[39m# bc we know arr.dtype == object, this is equivalent to\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[39m#  `np.asarray(to_timedelta(arr))`, but using a lower-level API that\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     \u001b[39m#  does not require a circular import.\u001b[39;00m\n\u001b[0;32m    159\u001b[0m     \u001b[39mreturn\u001b[39;00m array_to_timedelta64(arr)\u001b[39m.\u001b[39mview(\u001b[39m\"\u001b[39m\u001b[39mm8[ns]\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\tdoug\\miniconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1100\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1098\u001b[0m         result \u001b[39m=\u001b[39m _convert_and_box_cache(argc, cache_array)\n\u001b[0;32m   1099\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1100\u001b[0m         result \u001b[39m=\u001b[39m convert_listlike(argc, \u001b[39mformat\u001b[39;49m)\n\u001b[0;32m   1101\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1102\u001b[0m     result \u001b[39m=\u001b[39m convert_listlike(np\u001b[39m.\u001b[39marray([arg]), \u001b[39mformat\u001b[39m)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\tdoug\\miniconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:438\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mformat\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m infer_datetime_format\n\u001b[0;32m    437\u001b[0m utc \u001b[39m=\u001b[39m tz \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mutc\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 438\u001b[0m result, tz_parsed \u001b[39m=\u001b[39m objects_to_datetime64ns(\n\u001b[0;32m    439\u001b[0m     arg,\n\u001b[0;32m    440\u001b[0m     dayfirst\u001b[39m=\u001b[39;49mdayfirst,\n\u001b[0;32m    441\u001b[0m     yearfirst\u001b[39m=\u001b[39;49myearfirst,\n\u001b[0;32m    442\u001b[0m     utc\u001b[39m=\u001b[39;49mutc,\n\u001b[0;32m    443\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    444\u001b[0m     require_iso8601\u001b[39m=\u001b[39;49mrequire_iso8601,\n\u001b[0;32m    445\u001b[0m     allow_object\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    446\u001b[0m )\n\u001b[0;32m    448\u001b[0m \u001b[39mif\u001b[39;00m tz_parsed \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    449\u001b[0m     \u001b[39m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m    450\u001b[0m     \u001b[39m# is in UTC\u001b[39;00m\n\u001b[0;32m    451\u001b[0m     dta \u001b[39m=\u001b[39m DatetimeArray(result, dtype\u001b[39m=\u001b[39mtz_to_dtype(tz_parsed))\n",
      "File \u001b[1;32mc:\\Users\\tdoug\\miniconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:2177\u001b[0m, in \u001b[0;36mobjects_to_datetime64ns\u001b[1;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object, allow_mixed)\u001b[0m\n\u001b[0;32m   2175\u001b[0m order: Literal[\u001b[39m\"\u001b[39m\u001b[39mF\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mC\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mF\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m flags\u001b[39m.\u001b[39mf_contiguous \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mC\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2176\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 2177\u001b[0m     result, tz_parsed \u001b[39m=\u001b[39m tslib\u001b[39m.\u001b[39;49marray_to_datetime(\n\u001b[0;32m   2178\u001b[0m         data\u001b[39m.\u001b[39;49mravel(\u001b[39m\"\u001b[39;49m\u001b[39mK\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   2179\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   2180\u001b[0m         utc\u001b[39m=\u001b[39;49mutc,\n\u001b[0;32m   2181\u001b[0m         dayfirst\u001b[39m=\u001b[39;49mdayfirst,\n\u001b[0;32m   2182\u001b[0m         yearfirst\u001b[39m=\u001b[39;49myearfirst,\n\u001b[0;32m   2183\u001b[0m         require_iso8601\u001b[39m=\u001b[39;49mrequire_iso8601,\n\u001b[0;32m   2184\u001b[0m         allow_mixed\u001b[39m=\u001b[39;49mallow_mixed,\n\u001b[0;32m   2185\u001b[0m     )\n\u001b[0;32m   2186\u001b[0m     result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39mreshape(data\u001b[39m.\u001b[39mshape, order\u001b[39m=\u001b[39morder)\n\u001b[0;32m   2187\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOverflowError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m   2188\u001b[0m     \u001b[39m# Exception is raised when a part of date is greater than 32 bit signed int\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tdoug\\miniconda3\\envs\\myenv\\lib\\site-packages\\pandas\\_libs\\tslib.pyx:427\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\tdoug\\miniconda3\\envs\\myenv\\lib\\site-packages\\pandas\\_libs\\tslib.pyx:683\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\tdoug\\miniconda3\\envs\\myenv\\lib\\site-packages\\pandas\\_libs\\tslib.pyx:833\u001b[0m, in \u001b[0;36mpandas._libs.tslib._array_to_datetime_object\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\tdoug\\miniconda3\\envs\\myenv\\lib\\site-packages\\pandas\\_libs\\tslib.pyx:655\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: <class 'pandas.core.series.Series'> is not convertible to datetime"
     ]
    }
   ],
   "source": [
    " #create new dataframe with data broken down by line\n",
    "njt_lines=services['line'].unique()\n",
    "max_delays = pd.Series(helper.get_max_delay(services,njt_lines)).round(3)\n",
    "avg_delays = pd.Series(helper.get_avg_delay(services,njt_lines)).round(3)\n",
    "dates = pd.Series(helper.get_delay_date(services,njt_lines))\n",
    "\n",
    "print(dates)\n",
    "performance_by_line = pd.DataFrame({'Longest Delay (minutes)': max_delays.values,\n",
    "                                   'Average Delay (minutes)': avg_delays.values,\n",
    "                                   'Date of Longest Delay' : dates.values},\n",
    "                                    index=njt_lines)\n",
    "                    \n",
    "performance_by_line.astype({'Longest Delay (minutes)' :'float16',\n",
    "                            'Average Delay (minutes)' :'float16',\n",
    "                            'Date of Longest Delay' : 'datetime64'\n",
    "                            })\n",
    "\n",
    "performance_by_line"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of On-Time Performance by Rail Line\n",
    "\n",
    "    notes: Princeton Shuttle is outlier considering it's short trip distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = performance_by_line.plot.bar()\n",
    "ax"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "250b70949b6eb4b48e36940509b8103844f201ae3647754aee77af257d58d6ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
